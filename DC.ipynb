{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaec229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Standard Stable Diffusion pipeline: runwayml/stable-diffusion-v1-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:08<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STL-10 dataset (test split) from C:/Users/suzuryo/Desktop/env/dataset...\n",
      "Files already downloaded and verified\n",
      "Sampling 10 indices randomly for this experiment.\n",
      "Running experiments on a subset of 10 images.\n",
      "Pre-computing text embeddings for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding prompts: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings pre-computation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying 10 images with Standard SD 1.5: 100%|██████████| 10/10 [05:50<00:00, 35.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification loop finished. Starting analysis... ---\n",
      "Analyzing results using noise levels between 100 and 800 for majority vote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing results: 100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Accuracy for Majority Vote (Min Error) ---\n",
      "  -> Top-1 Accuracy: 90.00% (9/10)\n",
      "\n",
      "Releasing resources...\n",
      "\n",
      "--- Standard SD 1.5 analysis finished for STL-10 (Top-1 Min Error only). ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# ライブラリのインポート\n",
    "# ==============================================================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm \n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle \n",
    "\n",
    "# ==============================================================================\n",
    "# 1. パラメータとモデルの準備\n",
    "# ==============================================================================\n",
    "\n",
    "# --- モデル設定 ---\n",
    "# 使用する拡散モデルのリポジトリID\n",
    "STABLE_DIFFUSION_MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# --- データセット設定 ---\n",
    "# stl10_binaryが保存されているルートディレクトリ \n",
    "DATA_ROOT = \"./dataset\"\n",
    "\n",
    "# --- 実験パラメータ ---\n",
    "# 1画像あたりに評価するサンプリング回数\n",
    "SAMPLES_PER_IMAGE = 10\n",
    "# ノイズを加える際のタイムステップの最小・最大値\n",
    "NOISE_LEVEL_MIN = 100\n",
    "NOISE_LEVEL_MAX = 800\n",
    "# 実験に使用する画像の最大枚数 (Noneなら全画像)\n",
    "NUM_IMAGES_TO_TEST = 10 # デバッグ用に減らす\n",
    "# 乱数シード (再現性のため)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --- 計算デバイスと精度 ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Loading Standard Stable Diffusion pipeline: {STABLE_DIFFUSION_MODEL_ID}\")\n",
    "\n",
    "# --- モデルのロード ---\n",
    "# Stable Diffusion パイプライン\n",
    "pipe = StableDiffusionPipeline.from_pretrained(STABLE_DIFFUSION_MODEL_ID, torch_dtype=DTYPE).to(DEVICE)\n",
    "vae = pipe.vae\n",
    "tokenizer = pipe.tokenizer\n",
    "text_encoder = pipe.text_encoder\n",
    "unet = pipe.unet\n",
    "scheduler = pipe.scheduler\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. データセットのロード\n",
    "# ==============================================================================\n",
    "\n",
    "print(f\"Loading STL-10 dataset (test split) from {DATA_ROOT}...\")\n",
    "try:\n",
    "    # PIL画像を直接取得するため transform=None\n",
    "    stl10_dataset_pil = datasets.STL10(root=DATA_ROOT, split='test', download=True) # download=True (初回実行時)\n",
    "    class_names = stl10_dataset_pil.classes\n",
    "    NUM_CLASSES = len(class_names)\n",
    "except Exception as e:\n",
    "    print(f\"Error: Failed to load or download STL-10 dataset. Check the path: {DATA_ROOT}. Details: {e}\")\n",
    "    assert False\n",
    "\n",
    "# --- 実験対象サブセットの作成 ---\n",
    "all_indices = list(range(len(stl10_dataset_pil)))\n",
    "if NUM_IMAGES_TO_TEST and NUM_IMAGES_TO_TEST < len(stl10_dataset_pil):\n",
    "    print(f\"Sampling {NUM_IMAGES_TO_TEST} indices randomly for this experiment.\")\n",
    "    # random.sampleでインデックスをランダムに選ぶ\n",
    "    subset_indices = random.sample(all_indices, NUM_IMAGES_TO_TEST)\n",
    "else:\n",
    "    print(\"Using the full test dataset for this experiment.\")\n",
    "    subset_indices = all_indices\n",
    "print(f\"Running experiments on a subset of {len(subset_indices)} images.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ユーティリティ関数と事前計算\n",
    "# ==============================================================================\n",
    "\n",
    "# --- プロンプト生成関数 ---\n",
    "def create_prompt(class_idx):\n",
    "    \"\"\"クラスインデックスからプロンプト文字列を生成\"\"\"\n",
    "    name = class_names[class_idx]\n",
    "    return f\"a photo of a {name}\"\n",
    "\n",
    "# --- テキスト埋め込みの事前計算 ---\n",
    "print(\"Pre-computing text embeddings for all classes...\")\n",
    "with torch.no_grad():\n",
    "    uncond_input = tokenizer(\"\", padding=\"max_length\", max_length=tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(DEVICE))[0]\n",
    "    all_class_prompts = [create_prompt(i) for i in range(NUM_CLASSES)]\n",
    "    all_text_embeddings_list = []\n",
    "    batch_size = 64\n",
    "    for i in tqdm(range(0, len(all_class_prompts), batch_size), desc=\"Encoding prompts\"):\n",
    "        prompts_batch = all_class_prompts[i:i+batch_size]\n",
    "        text_inputs = tokenizer(prompts_batch, padding=\"max_length\", max_length=tokenizer.model_max_length, return_tensors=\"pt\", truncation=True)\n",
    "        batch_embeddings = text_encoder(text_inputs.input_ids.to(DEVICE))[0]\n",
    "        all_text_embeddings_list.append(batch_embeddings.cpu())\n",
    "    all_text_embeddings = torch.cat(all_text_embeddings_list, dim=0).to(DEVICE) # 全クラスの埋め込みをGPUに保持\n",
    "    print(\"Text embeddings pre-computation complete.\")\n",
    "\n",
    "\n",
    "# --- ノイズ予測誤差計算関数 (バッチ処理対応版) ---\n",
    "@torch.no_grad()\n",
    "def get_sd_noise_error_batched(init_latents, original_noise, text_embeds_batch, start_timestep):\n",
    "    \"\"\"指定されたタイムステップにおけるノイズ予測誤差をバッチ計算\"\"\"\n",
    "    noisy_latents = scheduler.add_noise(init_latents, original_noise, torch.tensor([start_timestep], device=DEVICE))\n",
    "    batch_size = text_embeds_batch.shape[0]\n",
    "    latent_model_input = noisy_latents.repeat(batch_size, 1, 1, 1)\n",
    "    timestep_input = torch.tensor([start_timestep], device=DEVICE).repeat(batch_size)\n",
    "    pred_noise_batch = unet(latent_model_input, timestep_input, encoder_hidden_states=text_embeds_batch).sample\n",
    "    original_noise_batch = original_noise.repeat(batch_size, 1, 1, 1)\n",
    "    mse_losses = F.mse_loss(pred_noise_batch, original_noise_batch, reduction='none').mean(dim=(1, 2, 3))\n",
    "    return mse_losses.cpu().numpy().tolist()\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. メイン実行ループ\n",
    "# ==============================================================================\n",
    "all_results = [] # 全画像の結果をメモリ上に格納するリスト\n",
    "sd_transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# 実験対象の画像インデックスに対してループ\n",
    "for image_index in tqdm(subset_indices, desc=f\"Classifying {len(subset_indices)} images with Standard SD 1.5\"):\n",
    "    # --- 画像のロードと前処理 ---\n",
    "    image_pil, true_label_idx = stl10_dataset_pil[image_index]\n",
    "    if image_pil.mode != 'RGB': image_pil = image_pil.convert('RGB')\n",
    "    image_tensor = sd_transform(image_pil).unsqueeze(0).to(DEVICE, dtype=DTYPE)\n",
    "\n",
    "    # --- VAEエンコード ---\n",
    "    with torch.no_grad():\n",
    "        init_latents = vae.encode(image_tensor).latent_dist.sample() * vae.config.scaling_factor\n",
    "\n",
    "    # --- 評価対象クラス ---\n",
    "    candidate_indices = list(range(NUM_CLASSES)) # 0から9までのインデックス\n",
    "\n",
    "    # --- テキスト埋め込みの準備 ---\n",
    "    candidate_embeds = all_text_embeddings\n",
    "    text_embeds_batch = torch.cat([uncond_embeddings, candidate_embeds])\n",
    "\n",
    "    # --- サンプリングループ ---\n",
    "    samples_data = []\n",
    "    for _ in range(SAMPLES_PER_IMAGE):\n",
    "        start_timestep = random.randint(NOISE_LEVEL_MIN, NOISE_LEVEL_MAX)\n",
    "        noise = torch.randn_like(init_latents)\n",
    "        # バッチ計算 (11プロンプト分)\n",
    "        all_errors = get_sd_noise_error_batched(init_latents, noise, text_embeds_batch, start_timestep)\n",
    "        sample_errors_mse = {'unconditional': all_errors[0]}\n",
    "        # 2番目以降が各クラス(0~9)の誤差に対応\n",
    "        for i, class_idx in enumerate(candidate_indices):\n",
    "            sample_errors_mse[class_idx] = all_errors[i+1]\n",
    "        samples_data.append({\n",
    "            'used_timestep': start_timestep,\n",
    "            'errors_mse': sample_errors_mse\n",
    "        })\n",
    "\n",
    "    # --- 画像ごとの結果を保存 ---\n",
    "    all_results.append({\n",
    "        'image_index': image_index,\n",
    "        'true_label': true_label_idx,\n",
    "        'candidates': candidate_indices, # 0~9のリスト\n",
    "        'samples': samples_data\n",
    "    })\n",
    "\n",
    "    # メモリ解放\n",
    "    del text_embeds_batch, init_latents, image_tensor\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Classification loop finished. Starting analysis... ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 結果の分析と表示\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 拡散モデルによる分類精度の集計 ---\n",
    "print(f\"Analyzing results using noise levels between {NOISE_LEVEL_MIN} and {NOISE_LEVEL_MAX} for majority vote.\")\n",
    "correct_count_min_error = 0 # Top-1の正解数のみカウント\n",
    "\n",
    "for res in tqdm(all_results, desc=\"Analyzing results\"):\n",
    "    true_label = res['true_label']\n",
    "    min_error_preds = []\n",
    "\n",
    "    for sample in res['samples']:\n",
    "        timestep = sample['used_timestep']\n",
    "        # 全てのタイムステップのサンプルを多数決に使用 (NOISE_LEVEL_MIN ~ MAX)\n",
    "        errors = sample['errors_mse']\n",
    "        candidate_errors = {k: v for k, v in errors.items() if k != 'unconditional'}\n",
    "\n",
    "        # 手法1: 最小誤差\n",
    "        if candidate_errors:\n",
    "            pred_min_error = min(candidate_errors, key=candidate_errors.get)\n",
    "            min_error_preds.append(pred_min_error)\n",
    "\n",
    "    # --- 多数決によるTop-1予測 ---\n",
    "    if min_error_preds: # 投票がある場合のみ\n",
    "        # 最も多く投票されたクラスを取得\n",
    "        majority_vote_pred = Counter(min_error_preds).most_common(1)[0][0]\n",
    "        # 正解と比較してカウント\n",
    "        if majority_vote_pred == true_label:\n",
    "            correct_count_min_error += 1\n",
    "\n",
    "# --- 全体精度の表示 ---\n",
    "total_images = len(all_results)\n",
    "top1_accuracy = (correct_count_min_error / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Accuracy for Majority Vote (Min Error) ---\")\n",
    "print(f\"  -> Top-1 Accuracy: {top1_accuracy:.2f}% ({correct_count_min_error}/{total_images})\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. リソースの解放\n",
    "# ==============================================================================\n",
    "print(\"\\nReleasing resources...\")\n",
    "del pipe, vae, tokenizer, text_encoder, unet, scheduler, all_text_embeddings, stl10_dataset_pil, all_results\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n--- Standard SD 1.5 analysis finished for STL-10 (Top-1 Min Error only). ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3467d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suzuryo\\.conda\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Stable Diffusion Inpainting pipeline: runwayml/stable-diffusion-inpainting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]An error occurred while trying to fetch C:\\Users\\suzuryo\\.cache\\huggingface\\hub\\models--runwayml--stable-diffusion-inpainting\\snapshots\\8a4288a76071f7280aedbdb3253bdb9e9d5d84bb\\unet: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\suzuryo\\.cache\\huggingface\\hub\\models--runwayml--stable-diffusion-inpainting\\snapshots\\8a4288a76071f7280aedbdb3253bdb9e9d5d84bb\\unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  29%|██▊       | 2/7 [00:05<00:12,  2.52s/it]An error occurred while trying to fetch C:\\Users\\suzuryo\\.cache\\huggingface\\hub\\models--runwayml--stable-diffusion-inpainting\\snapshots\\8a4288a76071f7280aedbdb3253bdb9e9d5d84bb\\vae: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\suzuryo\\.cache\\huggingface\\hub\\models--runwayml--stable-diffusion-inpainting\\snapshots\\8a4288a76071f7280aedbdb3253bdb9e9d5d84bb\\vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:08<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STL-10 dataset (test split) from C:/Users/suzuryo/Desktop/env/dataset...\n",
      "Files already downloaded and verified\n",
      "Sampling 10 indices randomly for this experiment.\n",
      "Running experiments on a subset of 10 images.\n",
      "Pre-computing text embeddings for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding prompts: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings pre-computation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying 10 images with Inpaint SD 1.5: 100%|██████████| 10/10 [00:35<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification loop finished. Starting analysis... ---\n",
      "Analyzing results using noise levels between 100 and 800 for majority vote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing results: 100%|██████████| 10/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Accuracy for Majority Vote (Min Error) ---\n",
      "  -> Top-1 Accuracy: 60.00% (6/10)\n",
      "\n",
      "Releasing resources...\n",
      "\n",
      "--- Inpaint SD 1.5 analysis finished for STL-10 (Top-1 Min Error only). ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# ライブラリのインポート\n",
    "# ==============================================================================\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# Inpaintingパイプラインを使用\n",
    "from diffusers import StableDiffusionInpaintPipeline, DDPMScheduler\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image, ImageDraw # マスク生成用に ImageDraw を追加\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm # プログレスバー表示用\n",
    "import os\n",
    "import gc # ガベージコレクション（メモリ解放）用\n",
    "import random\n",
    "import pickle # 結果表示に必要\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. パラメータとモデルの準備\n",
    "# ==============================================================================\n",
    "\n",
    "# --- モデル設定 ---\n",
    "# 使用する拡散モデルのリポジトリID (Inpaintingモデルに変更)\n",
    "INPAINT_MODEL_ID = \"runwayml/stable-diffusion-inpainting\"\n",
    "\n",
    "# --- データセット設定 ---\n",
    "# stl10_binaryが保存されているルートディレクトリ\n",
    "DATA_ROOT = \"./dataset\"\n",
    "\n",
    "# --- 実験パラメータ ---\n",
    "# 1画像あたりに評価するサンプリング回数\n",
    "SAMPLES_PER_IMAGE = 10\n",
    "# ノイズを加える際のタイムステップの最小・最大値\n",
    "NOISE_LEVEL_MIN = 100\n",
    "NOISE_LEVEL_MAX = 800\n",
    "# 実験に使用する画像の最大枚数 (Noneなら全画像)\n",
    "NUM_IMAGES_TO_TEST = 10 # デバッグ用に減らす\n",
    "# 乱数シード (再現性のため)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --- 計算デバイスと精度 ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Loading Stable Diffusion Inpainting pipeline: {INPAINT_MODEL_ID}\") # モデル名を変更\n",
    "\n",
    "# --- モデルのロード ---\n",
    "# Stable Diffusion Inpainting パイプライン\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(INPAINT_MODEL_ID, torch_dtype=DTYPE).to(DEVICE) # パイプラインクラスを変更\n",
    "vae = pipe.vae\n",
    "tokenizer = pipe.tokenizer\n",
    "text_encoder = pipe.text_encoder\n",
    "unet = pipe.unet\n",
    "scheduler = pipe.scheduler\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. データセットのロード\n",
    "# ==============================================================================\n",
    "\n",
    "print(f\"Loading STL-10 dataset (test split) from {DATA_ROOT}...\")\n",
    "try:\n",
    "    stl10_dataset_pil = datasets.STL10(root=DATA_ROOT, split='test', download=True)\n",
    "    class_names = stl10_dataset_pil.classes\n",
    "    NUM_CLASSES = len(class_names)\n",
    "except Exception as e:\n",
    "    print(f\"Error: Failed to load or download STL-10 dataset. Check the path: {DATA_ROOT}. Details: {e}\")\n",
    "    assert False\n",
    "\n",
    "all_indices = list(range(len(stl10_dataset_pil)))\n",
    "if NUM_IMAGES_TO_TEST and NUM_IMAGES_TO_TEST < len(stl10_dataset_pil):\n",
    "    print(f\"Sampling {NUM_IMAGES_TO_TEST} indices randomly for this experiment.\")\n",
    "    subset_indices = random.sample(all_indices, NUM_IMAGES_TO_TEST)\n",
    "else:\n",
    "    print(\"Using the full test dataset for this experiment.\")\n",
    "    subset_indices = all_indices\n",
    "print(f\"Running experiments on a subset of {len(subset_indices)} images.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ユーティリティ関数と事前計算\n",
    "# ==============================================================================\n",
    "\n",
    "# --- プロンプト生成関数 ---\n",
    "def create_prompt(class_idx):\n",
    "    \"\"\"クラスインデックスからプロンプト文字列を生成\"\"\"\n",
    "    name = class_names[class_idx]\n",
    "    return f\"a photo of a {name}\"\n",
    "\n",
    "# --- テキスト埋め込みの事前計算 ---\n",
    "print(\"Pre-computing text embeddings for all classes...\")\n",
    "with torch.no_grad():\n",
    "    uncond_input = tokenizer(\"\", padding=\"max_length\", max_length=tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(DEVICE))[0]\n",
    "    all_class_prompts = [create_prompt(i) for i in range(NUM_CLASSES)]\n",
    "    all_text_embeddings_list = []\n",
    "    batch_size = 64\n",
    "    for i in tqdm(range(0, len(all_class_prompts), batch_size), desc=\"Encoding prompts\"):\n",
    "        prompts_batch = all_class_prompts[i:i+batch_size]\n",
    "        text_inputs = tokenizer(prompts_batch, padding=\"max_length\", max_length=tokenizer.model_max_length, return_tensors=\"pt\", truncation=True)\n",
    "        batch_embeddings = text_encoder(text_inputs.input_ids.to(DEVICE))[0]\n",
    "        all_text_embeddings_list.append(batch_embeddings.cpu())\n",
    "    all_text_embeddings = torch.cat(all_text_embeddings_list, dim=0).to(DEVICE)\n",
    "    print(\"Text embeddings pre-computation complete.\")\n",
    "\n",
    "\n",
    "# --- ノイズ予測誤差計算関数 (Inpaintingモデル用 バッチ処理対応版) ---\n",
    "@torch.no_grad()\n",
    "def get_inpaint_noise_error_batched(\n",
    "    init_latents,       # 元画像の潜在表現 (1, 4, H/8, W/8)\n",
    "    original_noise,     # 加えるノイズ (1, 4, H/8, W/8)\n",
    "    text_embeds_batch,  # テキスト埋め込み (N+1, seq_len, embed_dim)\n",
    "    start_timestep,     # タイムステップ (int)\n",
    "    mask_tensor         # マスク画像テンソル (1, 1, H, W) float16\n",
    "):\n",
    "    \"\"\"Inpaintingモデルでノイズ予測誤差をマスク領域内で計算 (バッチ処理)\"\"\"\n",
    "    # 1. ノイズ付加\n",
    "    noisy_latents = scheduler.add_noise(init_latents, original_noise, torch.tensor([start_timestep], device=DEVICE))\n",
    "\n",
    "    # 2. マスクとマスク済み画像を潜在空間サイズにリサイズ\n",
    "    mask_latents = F.interpolate(mask_tensor, size=init_latents.shape[-2:]) # (1, 1, H/8, W/8)\n",
    "    # 元画像に反転マスクを掛けてマスク部分を0にする\n",
    "    masked_image_latents = init_latents * (1 - mask_latents) # (1, 4, H/8, W/8)\n",
    "\n",
    "    # 3. U-Netへの入力 (9チャンネル) をバッチ処理用に準備\n",
    "    batch_size = text_embeds_batch.shape[0]\n",
    "    # 各入力をバッチサイズ分複製\n",
    "    latent_model_input = noisy_latents.repeat(batch_size, 1, 1, 1) # (N+1, 4, ...)\n",
    "    mask_input = mask_latents.repeat(batch_size, 1, 1, 1)         # (N+1, 1, ...)\n",
    "    masked_input = masked_image_latents.repeat(batch_size, 1, 1, 1) # (N+1, 4, ...)\n",
    "    # チャンネル次元(dim=1)で結合 -> (N+1, 9, H/8, W/8)\n",
    "    final_input = torch.cat([latent_model_input, mask_input, masked_input], dim=1)\n",
    "    # タイムステップもバッチサイズ分用意\n",
    "    timestep_input = torch.tensor([start_timestep], device=DEVICE).repeat(batch_size)\n",
    "\n",
    "    # 4. U-Netでノイズ予測を実行\n",
    "    pred_noise_batch = unet(\n",
    "        final_input,\n",
    "        timestep_input,\n",
    "        encoder_hidden_states=text_embeds_batch\n",
    "    ).sample\n",
    "\n",
    "    # 5. 誤差(MSE)をマスク領域内のみで計算\n",
    "    # 元のノイズにマスクを掛ける\n",
    "    original_noise_masked = original_noise * mask_latents # (1, 4, H/8, W/8)\n",
    "    # バッチ内の各予測結果にもマスクを掛ける\n",
    "    pred_noise_batch_masked = pred_noise_batch * mask_latents # (N+1, 4, H/8, W/8)\n",
    "    # マスクされたノイズ同士でMSEを計算 (分母をマスク面積にするため工夫が必要だが、比較目的なら単純MSEでもOK)\n",
    "    # ここでは単純なMSEを計算 (F.mse_lossはゼロ除算を避けるため、マスク外も含む全ピクセルで計算されるが、マスク外は0*0になるので結果的にマスク内誤差に近い値になる)\n",
    "    mse_losses = F.mse_loss(pred_noise_batch_masked, original_noise_masked.repeat(batch_size, 1, 1, 1), reduction='none').mean(dim=(1, 2, 3))\n",
    "\n",
    "    # 6. 結果をPythonのリストとして返す\n",
    "    return mse_losses.cpu().numpy().tolist()\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. メイン実行ループ\n",
    "# ==============================================================================\n",
    "all_results = []\n",
    "sd_transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "# マスク画像をテンソルに変換するためのTransform\n",
    "mask_transform = transforms.ToTensor()\n",
    "\n",
    "# 実験対象の画像インデックスに対してループ\n",
    "for image_index in tqdm(subset_indices, desc=f\"Classifying {len(subset_indices)} images with Inpaint SD 1.5\"):\n",
    "    # --- 画像のロードと前処理 ---\n",
    "    image_pil, true_label_idx = stl10_dataset_pil[image_index]\n",
    "    if image_pil.mode != 'RGB': image_pil = image_pil.convert('RGB')\n",
    "    image_tensor = sd_transform(image_pil).unsqueeze(0).to(DEVICE, dtype=DTYPE)\n",
    "\n",
    "    # --- VAEエンコード ---\n",
    "    with torch.no_grad():\n",
    "        init_latents = vae.encode(image_tensor).latent_dist.sample() * vae.config.scaling_factor\n",
    "\n",
    "    # --- 評価対象クラス ---\n",
    "    candidate_indices = list(range(NUM_CLASSES))\n",
    "\n",
    "    # --- テキスト埋め込みの準備 ---\n",
    "    candidate_embeds = all_text_embeddings\n",
    "    text_embeds_batch = torch.cat([uncond_embeddings, candidate_embeds])\n",
    "    # --- サンプリングループ ---\n",
    "    samples_data = []\n",
    "    for _ in range(SAMPLES_PER_IMAGE):\n",
    "        # 1. ランダムなタイムステップを選択\n",
    "        start_timestep = random.randint(NOISE_LEVEL_MIN, NOISE_LEVEL_MAX)\n",
    "        # 2. ランダムなノイズを生成\n",
    "        noise = torch.randn_like(init_latents)\n",
    "        # 3. ランダムな部分マスクを生成\n",
    "        mask_pil = Image.new(\"L\", (512, 512), 0) # 黒背景のマスク画像\n",
    "        draw = ImageDraw.Draw(mask_pil)\n",
    "        # 目標面積率 (10% ~ 80%)\n",
    "        target_area_ratio = random.uniform(0.1, 0.8)\n",
    "        img_area = 512 * 512\n",
    "        mask_area = img_area * target_area_ratio\n",
    "        # ランダムなアスペクト比 (例: 0.3 ~ 3.0)\n",
    "        aspect_ratio = random.uniform(0.3, 3.0)\n",
    "        # 幅と高さを計算\n",
    "        mask_w = int(np.sqrt(mask_area / aspect_ratio))\n",
    "        mask_h = int(mask_w * aspect_ratio)\n",
    "        # 画像サイズ内に収める\n",
    "        mask_w = max(16, min(mask_w, 512))\n",
    "        mask_h = max(16, min(mask_h, 512))\n",
    "        # ランダムな位置\n",
    "        mask_x = random.randint(0, 512 - mask_w)\n",
    "        mask_y = random.randint(0, 512 - mask_h)\n",
    "        # マスクを描画 (白=255 で塗りつぶし)\n",
    "        draw.rectangle((mask_x, mask_y, mask_x + mask_w, mask_y + mask_h), fill=255)\n",
    "        # マスクをテンソルに変換\n",
    "        mask_tensor = mask_transform(mask_pil).unsqueeze(0).to(DEVICE, dtype=DTYPE) # (1, 1, 512, 512)\n",
    "\n",
    "        # 4. ノイズ予測誤差をバッチ計算 (Inpainting関数を使用)\n",
    "        all_errors = get_inpaint_noise_error_batched(\n",
    "            init_latents, noise, text_embeds_batch, start_timestep, mask_tensor\n",
    "        )\n",
    "\n",
    "        # 5. 結果を整理\n",
    "        sample_errors_mse = {'unconditional': all_errors[0]}\n",
    "        for i, class_idx in enumerate(candidate_indices):\n",
    "            sample_errors_mse[class_idx] = all_errors[i+1]\n",
    "        samples_data.append({\n",
    "            'used_timestep': start_timestep,\n",
    "            'errors_mse': sample_errors_mse\n",
    "        })\n",
    "\n",
    "    # --- 画像ごとの結果を保存 ---\n",
    "    all_results.append({\n",
    "        'image_index': image_index,\n",
    "        'true_label': true_label_idx,\n",
    "        'candidates': candidate_indices,\n",
    "        'samples': samples_data\n",
    "    })\n",
    "\n",
    "    # メモリ解放\n",
    "    del text_embeds_batch, init_latents, image_tensor, mask_tensor\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Classification loop finished. Starting analysis... ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 結果の分析と表示\n",
    "# ==============================================================================\n",
    "print(f\"Analyzing results using noise levels between {NOISE_LEVEL_MIN} and {NOISE_LEVEL_MAX} for majority vote.\")\n",
    "correct_count_min_error = 0\n",
    "\n",
    "for res in tqdm(all_results, desc=\"Analyzing results\"):\n",
    "    true_label = res['true_label']\n",
    "    min_error_preds = []\n",
    "    for sample in res['samples']:\n",
    "        errors = sample['errors_mse']\n",
    "        candidate_errors = {k: v for k, v in errors.items() if k != 'unconditional'}\n",
    "        if candidate_errors:\n",
    "            pred_min_error = min(candidate_errors, key=candidate_errors.get)\n",
    "            min_error_preds.append(pred_min_error)\n",
    "\n",
    "    if min_error_preds:\n",
    "        majority_vote_pred = Counter(min_error_preds).most_common(1)[0][0]\n",
    "        if majority_vote_pred == true_label:\n",
    "            correct_count_min_error += 1\n",
    "\n",
    "total_images = len(all_results)\n",
    "top1_accuracy = (correct_count_min_error / total_images) * 100 if total_images > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Accuracy for Majority Vote (Min Error) ---\")\n",
    "print(f\"  -> Top-1 Accuracy: {top1_accuracy:.2f}% ({correct_count_min_error}/{total_images})\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. リソースの解放\n",
    "# ==============================================================================\n",
    "print(\"\\nReleasing resources...\")\n",
    "del pipe, vae, tokenizer, text_encoder, unet, scheduler, all_text_embeddings, stl10_dataset_pil, all_results\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n--- Inpaint SD 1.5 analysis finished for STL-10 (Top-1 Min Error only). ---\") # メッセージ変更"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
